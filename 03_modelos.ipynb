{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd6fb1d-5ae4-4539-8958-32fdfe483cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d9eca-fab4-4c5c-84cb-2f6e2dabab1a",
   "metadata": {},
   "source": [
    "# modelos\n",
    "\n",
    "> Herramientas de ajuste, validación y evaluación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1ed2e-abfa-4684-9cbc-9cfe96da5c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d011ee-3ba4-41cc-8a80-79352e8e2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import warnings\n",
    "from functools import reduce\n",
    "from itertools import chain\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from libpysal.weights import Queen\n",
    "from esda.moran import Moran\n",
    "from splot.esda import moran_scatterplot\n",
    "import statsmodels.formula.api as smf \n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from criminologia_cdmx.etl import *\n",
    "from criminologia_cdmx.covariables import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de2ee8d-4713-4a5b-8a58-e01f5fe8f723",
   "metadata": {},
   "source": [
    "## variable_dependiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1286bf-5bcd-4665-8b53-69a53bf482b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def variable_dependiente(datos, columna_y, valores_y, \n",
    "                           fecha_inicio, fecha_fin, \n",
    "                           agregacion='colonias',\n",
    "                           nombre_y=None):\n",
    "    \"\"\" Regresa un DataFrame con la variable independicente agregada entre fecha_inicio y fecha_fin\n",
    "        en las unidades requeridas.\n",
    "        \n",
    "        Args:\n",
    "            datos (DataFrame): carpetas/victimas con ids espaciales y categorías de usuario\n",
    "            columna_y (str): Nombre de la columna en donde vienen los incidentes de valor_y\n",
    "            valores_y (list): delitos o categorías a utilizar como Y\n",
    "            fecha_inicio (str): fecha inicial para agregar delitos \"d-m-Y\"\n",
    "            fecha_fin (str): fecha final para agregar delitos \"d-m-Y\"\n",
    "            agregacion (str): colonias/cuadrantes. Eventualmente debe recibir \n",
    "                              agregaciones arbitrarias (opcional)\n",
    "            nombre_y (str): Nombre para la columna con la variable dependiente \n",
    "                           (opcional, si se omite se concatenan los nombres de valores_y).\n",
    "    \"\"\"\n",
    "    fecha_inicio = pd.to_datetime(fecha_inicio, dayfirst=True)\n",
    "    fecha_fin = pd.to_datetime(fecha_fin, dayfirst=True)\n",
    "    datos = datos.loc[datos['fecha_hechos'].between(fecha_inicio, fecha_fin)]\n",
    "    datos = datos.loc[datos[columna_y].isin(valores_y)]\n",
    "    if agregacion == 'colonias':\n",
    "        columna_agrega = 'colonia_cve'\n",
    "        layer = 'colonias'\n",
    "    elif agregacion == 'cuadrantes':\n",
    "        columna_agrega = 'cuadrante_id'\n",
    "        layer = 'cuadrantes'\n",
    "    else:\n",
    "        raise ValueError(\"unidades debe ser 'colonias' o 'cuadrantes'\")\n",
    "    datos = datos.groupby(columna_agrega).size()\n",
    "    if nombre_y is not None:\n",
    "        datos.name = nombre_y\n",
    "    else:\n",
    "        datos.name = \" \".join(valores_y)\n",
    "    \n",
    "    unidades = gpd.read_file(\"datos/criminologia_capas.gpkg\", layer=layer)\n",
    "    datos = unidades[[columna_agrega]].merge(datos, on=columna_agrega, how='left').fillna(0)\n",
    "    return datos   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca70794-7c50-4095-b3e7-5238e36467fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "carpetas = get_carpetas_from_api(100000)\n",
    "carpetas = agrega_ids_espaciales(carpetas)\n",
    "fecha_inicio = carpetas.fecha_hechos.min().strftime(\"%d-%m.%Y\")\n",
    "fecha_fin = carpetas.fecha_hechos.max().strftime(\"%d-%m.%Y\")\n",
    "# Prueba con un delito\n",
    "delito = ['ROBO A CASA HABITACION SIN VIOLENCIA']\n",
    "Y = variable_dependiente(carpetas, 'delito', delito, fecha_inicio, fecha_fin, \n",
    "                           agregacion='cuadrantes')\n",
    "assert delito[0] in Y.columns\n",
    "Y = variable_dependiente(carpetas, 'delito', delito, fecha_inicio, fecha_fin)\n",
    "assert delito[0] in Y.columns\n",
    "# Prueba con dos delitos y nombre de columna\n",
    "delitos = ['ROBO A CASA HABITACION SIN VIOLENCIA', 'ROBO A CASA HABITACION CON VIOLENCIA']\n",
    "nombre_y = \"Robo a Casa habitación (CV/SV)\"\n",
    "Y = variable_dependiente(carpetas, 'delito', delitos, fecha_inicio, fecha_fin, \n",
    "                           agregacion='cuadrantes', nombre_y=nombre_y)\n",
    "assert nombre_y in Y.columns\n",
    "Y = variable_dependiente(carpetas, 'delito', delitos, fecha_inicio, fecha_fin, \n",
    "                           nombre_y=nombre_y)\n",
    "assert nombre_y in Y.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55918ba4-8b06-407d-9cf5-26224781dcc2",
   "metadata": {},
   "source": [
    "## CapaDeAnalisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374abc5e-ea35-412d-ab96-bbf06a16ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CapaDeAnalisis(object):\n",
    "    \"\"\" Clase para contener variable objetivo y covariables.\n",
    "    \n",
    "        Args:\n",
    "            Y (DataFrame): debe tener dos columnas: el identificador de la unidad de análisis y \n",
    "                           el valor de la variable dependiente \n",
    "                           (las columnas deben venir en ese orden).\n",
    "            covariables (DataFrame): debe contener una columna con el identificador de la unidad \n",
    "                                     de análisis (común a Y) y tantas como covariables.\n",
    "            agregación (str): colonias/cuadrantes.\n",
    "        Atributos:\n",
    "            Y (DataFrame): la variable dependiente.\n",
    "            Y_nombre (str): Nombre de la columna con el delito a modelar.\n",
    "            X (DataFrame): las variables independientes.\n",
    "            X_nombres (list): Lista de los nombres de columnas de las covariables.\n",
    "            agregacion (str): colonias/cuadrantes.\n",
    "            campo_id (str): el nombre del campo común en X y Y para unirlos.\n",
    "            df (DataFrame): la unión de los dos X y Y.\n",
    "            geo (GeoDataFrame): la unión de df con las geometrias que corresponden a `agregacion`\n",
    "            w (libpysal.weights.Queen): Matriz de vecindad para los datos válidos\n",
    "            \n",
    "        **NOTAS:** \n",
    "            1) El DataFrame con los datos finales va a contener sólo las observaciones válidas\n",
    "            (sin nulos en Y o X), además, para poder hacer análisis espaciales, se eliminan los\n",
    "            polígonos isla.\n",
    "            \n",
    "            2) Por lo pronto la clase calcula automáticamente una matriz de vecindad para los\n",
    "            datos, en el futuro esto debe cambiar para permitir al usuario definir su propia matriz.\n",
    "                   \n",
    "                   \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, Y, covariables, agregacion='colonias'):\n",
    "        self.Y = Y\n",
    "        self.Y_nombre = Y.columns[-1]\n",
    "        self.X = covariables\n",
    "        self.campo_id = self.__get_campo_id(agregacion)\n",
    "        self.X_nombres = [x for x in covariables.columns if x != self.campo_id]\n",
    "        self.agregacion = agregacion       \n",
    "        self.df = self.__merge_covars()\n",
    "        self.geo = self.__get_geo(agregacion)\n",
    "        self.w = self.__calcula_matriz_pesos()\n",
    "        # TODO self_repr() una función que describa en texto lo que pasó (datos válidos, etc.)\n",
    "        \n",
    "    def __merge_covars(self):\n",
    "        \"\"\"Regresa la unión de X y Y.\"\"\"\n",
    "        # TODO: aquí hay que contar cuántos datos perdimos por valores faltantes\n",
    "        df = (self.Y.merge(self.X, on=self.campo_id)\n",
    "                    .replace([np.inf, -np.inf], np.nan)\n",
    "                    .dropna())\n",
    "        return df\n",
    "    \n",
    "    def __get_campo_id(self, agregacion):\n",
    "        \"\"\" Regresa la columna que une los dataframes.\"\"\"\n",
    "        if agregacion == 'colonias':\n",
    "            campo_id = 'colonia_cve'\n",
    "        elif agregacion == 'cuadrantes':\n",
    "            campo_id = 'cuadrante_id'\n",
    "        else:\n",
    "            raise ValueError(\"agregacion debe ser colonias o cuadrantes.\")\n",
    "        return campo_id\n",
    "    \n",
    "    def __get_geo(self, agregacion):\n",
    "        \"\"\" Regresa el GeoDataframe correspondiente a la agregación.\"\"\"\n",
    "        geo = gpd.read_file(\"datos/criminologia_capas.gpkg\", layer=agregacion)\n",
    "        geo = geo.merge(self.df, on=self.campo_id, how='inner')\n",
    "        return geo\n",
    "    \n",
    "    def __calcula_matriz_pesos(self):\n",
    "        \"\"\"Regresa la matriz de peso y actualiza geo y df para eliminar las islas.\"\"\"\n",
    "        # TODO: aquí hay que contar los datos perdidos por islas\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            w = Queen.from_dataframe(self.geo)\n",
    "            if len(w.islands):\n",
    "                self.df.drop(w.islands, inplace=True)\n",
    "                self.geo.drop(w.islands, inplace=True)\n",
    "                w = Queen.from_dataframe(self.geo)\n",
    "        return w\n",
    "    \n",
    "    \n",
    "    def displot_Y(self, size=(12,6)):\n",
    "        \"\"\"Regresa el histograma de la variable dependiente.\"\"\"\n",
    "        f, ax = plt.subplots(1,figsize=size)\n",
    "        ax = sns.histplot(data=self.Y, x=self.Y_nombre, ax=ax)\n",
    "        ax.axvline(x=self.Y[self.Y_nombre].mean(), color='red')\n",
    "        ax.set_ylabel(\"Conteo\")\n",
    "        return ax\n",
    "    \n",
    "    def pairplot_X(self, altura=10, ratio=1):\n",
    "        \"\"\"Regresa un pairplot de las variables independientes.\"\"\"\n",
    "        return sns.pairplot(self.X)\n",
    "    \n",
    "    def describe_Y(self):\n",
    "        \"\"\"Regresa un DataFrame con estadísticas descriptivas de la variable dependiente.\"\"\"\n",
    "        d = self.Y[self.Y_nombre].describe()\n",
    "        v = pd.Series({\"Var\":self.Y[self.Y_nombre].var()})\n",
    "        d = d.append(v)\n",
    "        d = pd.DataFrame(d)\n",
    "        d = d.reset_index()\n",
    "        d.columns = ['Estadístico', '']\n",
    "        d = d.set_index('Estadístico')\n",
    "        orden = ['count', 'mean','Var',  'std', 'min', '25%', '50%', '75%', 'max']\n",
    "        d = d.reindex(orden)\n",
    "        d = d.rename({'count': 'N', 'mean': 'Media', \n",
    "                      'Var':'Varianza', \n",
    "                      'std': 'Desviación estándar',\n",
    "                      'min': 'Mínimo',\n",
    "                      'max': 'Máximo'})\n",
    "        return d\n",
    "        \n",
    "    def mapa_Y(self, agregacion, ax=None, \n",
    "               size=(10,10), clasificacion='quantiles', \n",
    "               cmap='YlOrRd', legend=True):\n",
    "        \"\"\" Regresa un ax con el mapa de la variable dependiente.\n",
    "        \n",
    "            Args:\n",
    "            agregacion (str): colonias/cuadrantes\n",
    "            ax (matplotlib.plot.ax): el eje en donde se hace el mapa (opcional, default None)\n",
    "            size ((int,int)): tamaño del mapa (opcional, si se pasa un eje se ignora)\n",
    "            clasificacion (str): esquema de clasificación demapclassify (opcional)\n",
    "            cmap (str): mapa de colores de matplotlib (opcional)\n",
    "            legend (bool): poner o no poner la leyenda (opcional)\n",
    "        \"\"\"\n",
    "        capa = gpd.read_file(\"datos/criminologia_capas.gpkg\", layer=agregacion)\n",
    "        capa = capa.merge(self.Y, on=self.campo_id)\n",
    "        if ax is None:\n",
    "            f, ax = plt.subplots(1,figsize=size)\n",
    "        ax = capa.plot(self.Y_nombre, scheme=clasificacion, ax=ax, cmap=cmap, legend=legend)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(self.Y_nombre)\n",
    "        return ax\n",
    "    \n",
    "    def mapa_X(self, covariable, agregacion, ax=None, \n",
    "               size=(10,10), clasificacion='quantiles', \n",
    "               cmap='YlOrRd', legend=True):\n",
    "        \"\"\" Regresa un ax con el mapa de la variable dependiente.\n",
    "        \n",
    "            Args:\n",
    "            covariable (str): Nombre de la columna en X para hacer el mapa\n",
    "            agregacion (str): colonias/cuadrantes\n",
    "            ax (matplotlib.plot.ax): el eje en donde se hace el mapa (opcional, default None)\n",
    "            size ((int,int)): tamaño del mapa (opcional, si se pasa un eje se ignora)\n",
    "            clasificacion (str): esquema de clasificación demapclassify (opcional)\n",
    "            cmap (str): mapa de colores de matplotlib (opcional)\n",
    "            legend (bool): poner o no poner la leyenda (opcional)\n",
    "        \"\"\"\n",
    "        capa = gpd.read_file(\"datos/criminologia_capas.gpkg\", layer=agregacion)\n",
    "        capa = capa.merge(self.X, on=self.campo_id)\n",
    "        if ax is None:\n",
    "            f, ax = plt.subplots(1,figsize=size)\n",
    "        ax = capa.plot(covariable, scheme=clasificacion, ax=ax, cmap=cmap, legend=legend)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(covariable)\n",
    "        return ax\n",
    "        \n",
    "    # TODO: \n",
    "    # agregar/quitar variables\n",
    "    # checar que exista el campo_id en las dos bases\n",
    "    # quitamos unas filas, hay que llevar registro de eso\n",
    "    # Calcular variables con retraso espacial\n",
    "    # Implementar transformadores sobre las variables\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe366ab-d0cc-4627-ac19-a58231700045",
   "metadata": {},
   "outputs": [],
   "source": [
    "usos = get_uso_de_suelo()\n",
    "usos = agrega_uso_suelo(usos, unidades='colonias')\n",
    "ca = CapaDeAnalisis(Y, usos, 'colonias')\n",
    "assert ca.X.equals(usos)\n",
    "assert ca.Y.equals(Y)\n",
    "assert type(ca.describe_Y()) == pd.DataFrame\n",
    "assert ca.geo.shape[0] == ca.df.shape[0]\n",
    "# TODO: pruebas a las gráficas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc96a5d6-7daa-4cb6-83db-dd068883d17e",
   "metadata": {},
   "source": [
    "## ModeloGLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8a618c-65e6-454f-ae94-79d0c34979d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ModeloGLM(object):\n",
    "    \"\"\" Wrapper para modelos de Regresión GLM de statsmodels.\n",
    "        \n",
    "        La clase prepara y ajusta un modelo GLM usando la variable objetivo\n",
    "        definida en CapaDeAnalisis y **todas** las covariables.\n",
    "        \n",
    "        Args:\n",
    "            capa (CapaDeAnalisis): objeto con las variables del modelo.\n",
    "            familia (statsmodels.api.families.Family()) la distribución a usar en el modelo GLM.\n",
    "            nombre (str): si no es nulo, el nombre, si no, se asigna nombre al azar.\n",
    "            \n",
    "        Atributos:\n",
    "            capa (CapaDeAnalisis): objeto con las variables del modelo.\n",
    "            familia (statsmodels.api.families.Family()) la distribución a usar en el modelo GLM.\n",
    "            formula (str): la fórmula usada para ajustar el modelo.\n",
    "            df_resultado (DataFrame): los resultados como DataFrame.\n",
    "            df_diagnostico (DataFrame): los diagnósticos como DataFrame.\n",
    "            nombre (str): nombre que identifica al modelo.\n",
    "        Métodos:\n",
    "            fit(): Ajusta el modelo.\n",
    "            grafica_de_ajuste(): regresa la gráfica de ajuste.\n",
    "    \"\"\"\n",
    "    def __init__(self, capa, familia, nombre=None):\n",
    "        self.capa = capa\n",
    "        self.familia = familia\n",
    "        self.nombre = self.__get_nombre(nombre)\n",
    "        self.formula = self.__get_formula()\n",
    "        self.__modelo = self.__get_modelo()\n",
    "        self.modelo_ajustado = None\n",
    "        self.df_resultado = None\n",
    "        self.df_diagnostico = None\n",
    "        self.gdf_residuales = None\n",
    "        self.moran_p_residuales = None\n",
    "        self.moran_dev_residuales = None\n",
    "\n",
    "    def __get_nombre(self, nombre):\n",
    "        if nombre is None:\n",
    "            letters = string.ascii_lowercase\n",
    "            return ''.join(random.choice(letters) for i in range(5))\n",
    "        else:\n",
    "            return nombre\n",
    "        \n",
    "    def __get_formula(self):\n",
    "        ls = f\"Q('{self.capa.Y_nombre}') ~ \"\n",
    "        rs = \"\"\n",
    "        for nombre in self.capa.X_nombres:\n",
    "            rs += f\"Q('{nombre}') + \"        \n",
    "        formula = ls + rs\n",
    "        formula = formula[:-3]\n",
    "        return formula\n",
    "    \n",
    "    def __get_modelo(self):\n",
    "        modelo = smf.glm(formula = self.formula,\n",
    "                         data    = self.capa.df, \n",
    "                         family  = self.familia)\n",
    "        return modelo\n",
    "    \n",
    "    def __resultados_a_df(self, resultados):\n",
    "        \"\"\"LLena self.df_resultado con los resultados del ajuste.\"\"\"\n",
    "        results_df = pd.DataFrame({\"coef\":resultados.params,\n",
    "                                   \"std err\": resultados.bse,\n",
    "                                   \"z\": resultados.tvalues,\n",
    "                                   \"P>|z|\":resultados.pvalues,\n",
    "                                   \"conf_lower\":resultados.conf_int()[0],\n",
    "                                   \"conf_higher\":resultados.conf_int()[1]\n",
    "                                    })\n",
    "        self.df_resultado = results_df\n",
    "\n",
    "    def __diagnostico_a_df(self, resultados):\n",
    "        \"\"\"LLena self.df_diagnostico con los resultados del ajuste.\"\"\"\n",
    "        indice = [\"Log-Likelihood\", \"Deviance\", \"Pearson chi2\"]\n",
    "        valores = [resultados.llf, resultados.deviance, resultados.pearson_chi2]\n",
    "        results_df = pd.DataFrame({\"Diagnóstico\": indice, \"Valor\": valores})\n",
    "        self.df_diagnostico = results_df\n",
    "    \n",
    "    def __residuales_gdf(self, resultados):\n",
    "        \"\"\" Llena el campo gdf_residuales.\"\"\"\n",
    "        resid_dev = resultados.resid_deviance.copy()\n",
    "        resid_dev = stats.zscore(resid_dev)\n",
    "        resid_df = pd.DataFrame(resid_dev, columns=[\"Residual Deviance\"])  \n",
    "        resid_p = resultados.resid_pearson\n",
    "        resid_p = pd.DataFrame(resid_p, columns=[\"Residual Pearson\"])\n",
    "        resid_df = resid_df.join(resid_p)\n",
    "        mapa_residuales = self.capa.Y.join(resid_df, how='right')\n",
    "        geos = gpd.read_file(\"datos/criminologia_capas.gpkg\",\n",
    "                             capa=self.capa.agregacion)\n",
    "        mapa_residuales = geos.merge(mapa_residuales, on=self.capa.campo_id)\n",
    "        self.gdf_residuales = mapa_residuales\n",
    "        \n",
    "    def __calcula_moran_residuales(self):\n",
    "        moran_dev = Moran(self.gdf_residuales['Residual Deviance'].values, self.capa.w)\n",
    "        self.moran_dev_residuales = moran_dev\n",
    "        moran_p = Moran(self.gdf_residuales['Residual Pearson'].values, self.capa.w)\n",
    "        self.moran_p_residuales = moran_p\n",
    "        \n",
    "    def fit(self):\n",
    "        \"\"\" Ajusta el modelo y llena los campos correspondientes.\n",
    "        \n",
    "            modelo_ajustado\n",
    "            df_resultado\n",
    "            df_diagnostico\n",
    "            gdf_residuales\n",
    "            moran_p_residuales\n",
    "            moran_dev_residuales\n",
    "        \"\"\"\n",
    "        fm = self.__modelo.fit()\n",
    "        self.modelo_ajustado = fm\n",
    "        self.__resultados_a_df(fm)\n",
    "        self.__diagnostico_a_df(fm)\n",
    "        self.__residuales_gdf(fm)\n",
    "        self.__calcula_moran_residuales()\n",
    "        return fm\n",
    "    \n",
    "    def grafica_de_ajuste(self, size=(10,5), ax=None):\n",
    "        \"\"\" Regresa un ax con la gráfica de ajuste del modelo.\n",
    "        \n",
    "            Args:\n",
    "            \n",
    "                size ((int,int)): Tamaño de la figura (opcional default (10,5)) \n",
    "                                  si ax !=None, se ignora\n",
    "                ax (matplotlib.axes): Eje en el que se grafica (opcional, default None)\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            f, ax = plt.subplots(1,figsize=size)\n",
    "        y =  self.capa.df[self.capa.Y_nombre].values\n",
    "        ax = sns.regplot(x=self.modelo_ajustado.mu, y=y, ax=ax)\n",
    "        ax.set_title('Gráfica de Ajuste del Modelo')\n",
    "        ax.set_ylabel('Valores observados')\n",
    "        ax.set_xlabel('Valores ajustados')\n",
    "        return ax\n",
    "    \n",
    "    def grafica_residuales(self, tipo=\"deviance\", size=(10,5), ax=None):\n",
    "        \"\"\" Regresa un ax con la gráfica de Dependencia de los Residuales.\n",
    "        \n",
    "            Args:\n",
    "            \n",
    "                size ((int,int)): Tamaño de la figura (opcional default (10,5)) \n",
    "                                  si ax !=None, se ignora\n",
    "                ax (matplotlib.axes): Eje en el que se grafica (opcional, default None)       \n",
    "        \"\"\"\n",
    "        observados = self.capa.df[self.capa.Y_nombre].values\n",
    "        if tipo == \"deviance\":\n",
    "            y = self.modelo_ajustado.resid_deviance\n",
    "            y_label = \"Residual (Deviance)\"\n",
    "        else:\n",
    "            y = self.modelo_ajustado.resid_pearson\n",
    "            y_label = \"Residual (Pearson)\"\n",
    "        if ax is None:\n",
    "            f, ax = plt.subplots(1,figsize=size)\n",
    "        ax = sns.scatterplot(x=observados, y=y, ax=ax)\n",
    "        ax.hlines(0, 0, observados.max(), colors='black')\n",
    "        ax.set_title('Gráfica de Dependencia de los Residuales')\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_xlabel('Valores ajustados')\n",
    "        return ax   \n",
    "    \n",
    "    def histograma_deviance(self, size=(10,5), ax=None):\n",
    "        \"\"\" Regresa un ax con el hitograma de deviance de los residuales.\n",
    "        \n",
    "            Args:\n",
    "            \n",
    "                size ((int,int)): Tamaño de la figura (opcional default (10,5)) \n",
    "                                  si ax !=None, se ignora\n",
    "                ax (matplotlib.axes): Eje en el que se grafica (opcional, default None)\n",
    "        \"\"\"\n",
    "        resid = self.modelo_ajustado.resid_deviance.copy()\n",
    "        resid_std = stats.zscore(resid)\n",
    "        resid_std = pd.DataFrame(resid_std, columns=[\"Desviación\"])\n",
    "        if ax is None:\n",
    "            f, ax = plt.subplots(1,figsize=size)\n",
    "        ax = sns.histplot(data=resid_std, x=\"Desviación\", ax=ax)\n",
    "        ax.set_title('Histograma de desviación estandarizada')\n",
    "        ax.set_ylabel('Conteo')\n",
    "        return ax\n",
    "    \n",
    "    def mapa_residuales(self, tipo=\"deviance\", size=(10,10), ax=None,\n",
    "                        clasificacion='quantiles', \n",
    "                        cmap='YlOrRd', legend=True):\n",
    "        \"\"\" Regresa un ax con el mapa de residuales (deviance/pearson)\n",
    "        \n",
    "            Args:\n",
    "            \n",
    "                agregacion (str): colonias/cuadrantes\n",
    "                ax (matplotlib.plot.ax): el eje en donde se hace el mapa (opcional, default None)\n",
    "                size ((int,int)): tamaño del mapa (opcional, si se pasa un eje se ignora)\n",
    "                clasificacion (str): esquema de clasificación demapclassify (opcional)\n",
    "                cmap (str): mapa de colores de matplotlib (opcional)\n",
    "                legend (bool): poner o no poner la leyenda (opcional)\n",
    "        \n",
    "        \"\"\"\n",
    "        observados = self.capa.df[self.capa.Y_nombre].values\n",
    "        if tipo == \"deviance\":\n",
    "            y = self.modelo_ajustado.resid_deviance\n",
    "            y_label = \"Residual Deviance\"\n",
    "        else:\n",
    "            y = self.modelo_ajustado.resid_pearson\n",
    "            y_label = \"Residual Pearson\"\n",
    "        if ax is None:\n",
    "            f, ax = plt.subplots(1,figsize=size)\n",
    "        ax = self.gdf_residuales.plot(y_label, \n",
    "                                      ax=ax, scheme=clasificacion, cmap=cmap, legend=legend)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(\"Mapa de residuales\")\n",
    "        return ax\n",
    "    \n",
    "    def scatterpĺot_moran(self, tipo=\"deviance\", ax=None):\n",
    "        \"\"\" Regresa un ax con el diagrama de dispersión de Moran para los residuales.\n",
    "        \n",
    "            Args:\n",
    "            \n",
    "                tipo (str): deviance/pearson el tipo de residuales a graficar, \n",
    "                            (opcional, default=deviance) .\n",
    "                size ((int,int)): Tamaño de la figura (opcional default (10,5)) \n",
    "                                  si ax !=None, se ignora\n",
    "                ax (matplotlib.axes): Eje en el que se grafica (opcional, default None)        \n",
    "        \"\"\"\n",
    "        if tipo == \"deviance\":\n",
    "            x_label = \"Residual Deviance\"\n",
    "            moran = self.moran_dev_residuales\n",
    "        elif tipo == \"pearson\":\n",
    "            x_label = \"Residual Pearson\"\n",
    "            moran = self.moran_p_residuales            \n",
    "        else:\n",
    "            raise ValueError(\"El tipo debe ser 'Residual Deviance' o 'Residual Pearson'\")\n",
    "        if ax is None:\n",
    "            fig, ax = moran_scatterplot(moran, aspect_equal=True)\n",
    "            ax.set_ylabel(\"Retraso espacial\")\n",
    "            ax.set_xlabel(x_label)\n",
    "            ax.set_title(f\"I de Moran {np.round(moran.I, 3)}, Significancia {moran.p_sim}\")\n",
    "        else:\n",
    "            moran_scatterplot(moran, aspect_equal=True, ax=ax)\n",
    "            ax.set_ylabel(\"Retraso espacial\")\n",
    "            ax.set_xlabel(x_label)\n",
    "            ax.set_title(f\"I de Moran {np.round(moran.I, 3)}, Significancia {moran.p_sim}\")\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190feb7-b960-465c-aad5-77c654043951",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ModeloGLM(ca, sm.families.NegativeBinomial())\n",
    "fm = m.fit()\n",
    "assert type(m.df_resultado) == pd.DataFrame\n",
    "assert type(m.df_diagnostico) == pd.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45934b39-a2cc-4185-ba0c-f78a1da5ff95",
   "metadata": {},
   "source": [
    "## ComparaModelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b94dcd-5c21-420f-97a7-2f15fd2c19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ComparaModelos(object):\n",
    "    \"\"\" Clase para construir comparaciones de modelos.\n",
    "        Construte dos DataFrames para visualizar rápidamente una comparación de los modelos:\n",
    "        uno con los resultados (coeficientes, etc) y otro con los diagnósticos.\n",
    "        Args:\n",
    "            modelos (list): Lista de modelos a comparar\n",
    "            columnas (list): Lista de columnas que aparecen en la comparación de resultados \n",
    "                             (opcional, default None)\n",
    "            redondeo: (int): Decimales a usar en la comparaciónn (opcional, default None)\n",
    "        Atributos:\n",
    "            modelos (list): Lista de modelos a comparar\n",
    "            comparacion (DataFrame): comparación de los resultados\n",
    "    \"\"\"\n",
    "    def __init__(self, modelos, columnas=None, redondeo=None):\n",
    "        self.modelos = modelos\n",
    "        self.comparacion = self.__une_resultados(columnas, redondeo)\n",
    "        self.diagnosticos = self.__une_diagnosticos(redondeo)\n",
    "    def __une_resultados(self, columnas, redondeo):\n",
    "        if columnas is None:\n",
    "            unidos = reduce(lambda left, right: \n",
    "                            left.df_resultado.join(right.df_resultado, \n",
    "                                                   how='outer', \n",
    "                                                   lsuffix=\"-\" + left.nombre,\n",
    "                                                   rsuffix=\"-\" + right.nombre)\n",
    "                            ,self.modelos)\n",
    "        else:\n",
    "            dfs = [(m.df_resultado, m.nombre) for m in self.modelos]\n",
    "            dfs = [(df[0][columnas], df[1]) for df in dfs]\n",
    "            unidos = reduce(lambda left, right: \n",
    "                            left[0].join(right[0], \n",
    "                                      how='outer', \n",
    "                                      lsuffix=\"-\" + left[1],\n",
    "                                      rsuffix=\"-\" + right[1])\n",
    "                            ,dfs)\n",
    "            \n",
    "        orden = [list(m.df_resultado.index) for m in self.modelos]\n",
    "        orden = list(set().union(*orden))\n",
    "        unidos = unidos.reindex(orden)\n",
    "        if columnas is None:\n",
    "            valores = self.modelos[0].df_resultado.columns\n",
    "        else:\n",
    "            valores = columnas\n",
    "        nombres = [\"Modelo \" + m.nombre for m in self.modelos]\n",
    "        indice_nuevo = pd.MultiIndex.from_product([nombres, valores])\n",
    "        unidos.columns = indice_nuevo\n",
    "        if redondeo:\n",
    "            unidos = unidos.round(redondeo)\n",
    "        return  unidos\n",
    "    \n",
    "    def __une_diagnosticos(self, redondeo):\n",
    "        unidos = reduce(lambda left, right: \n",
    "                        left.df_diagnostico.merge(right.df_diagnostico, \n",
    "                                                  on=\"Diagnóstico\",\n",
    "                                                  suffixes=(\" Modelo \" + left.nombre, \n",
    "                                                            \" Modelo \" + right.nombre)),\n",
    "                        self.modelos)\n",
    "        if redondeo:\n",
    "            unidos = unidos.round(redondeo)\n",
    "        return unidos\n",
    "        \n",
    "    def graficas_de_ajuste(self, n_cols=2, size=(20,5)):\n",
    "        \"\"\" Gráficas de ajuste para todos los modelos.\n",
    "        \n",
    "            Args:\n",
    "            \n",
    "                n_cols (int): Número de columnas en la figura\n",
    "                size ((int, int)): Tamaño de la figura\n",
    "        \"\"\"\n",
    "        n_modelos = len(self.modelos)\n",
    "        filas = math.ceil(n_modelos / n_cols)\n",
    "        f, axs = plt.subplots(filas, n_cols, figsize=size)\n",
    "        f.suptitle('Gráficas de ajuste', fontsize=16)\n",
    "        axs = axs.ravel()\n",
    "        for i, ax in enumerate(axs):\n",
    "            ax = self.modelos[i].grafica_de_ajuste(ax=ax)\n",
    "            ax.set_title(f\"{self.modelos[i].nombre}\")\n",
    "            \n",
    "    def graficas_residuales(self, tipo='deviance', n_cols=2, size=(20,5)):\n",
    "        \"\"\" Gráficas de residuales para todos los modelos.\n",
    "        \n",
    "        \n",
    "            Args:\n",
    "             \n",
    "                tipo (str): pearson/deviance tipo de residuales a graficar.\n",
    "                n_cols (int): Número de columnas en la figura.\n",
    "                size ((int, int)): Tamaño de la figura.\n",
    "        \n",
    "        \"\"\"\n",
    "        n_modelos = len(self.modelos)\n",
    "        filas = math.ceil(n_modelos / n_cols)\n",
    "        f, axs = plt.subplots(filas, n_cols, figsize=size)\n",
    "        f.suptitle('Gráficas de residuales', fontsize=16)        \n",
    "        axs = axs.ravel()\n",
    "        for i, ax in enumerate(axs):\n",
    "            ax = self.modelos[i].grafica_residuales(tipo=tipo, ax=ax)\n",
    "            ax.set_title(f\"{self.modelos[i].nombre}\")\n",
    "            \n",
    "    def histogramas_deviance(self, n_cols=2, size=(20,5)):\n",
    "        \"\"\" Histogramas de deviance para todos los modelos.\n",
    "        \n",
    "            Args:\n",
    "             \n",
    "                n_cols (int): Número de columnas en la figura.\n",
    "                size ((int, int)): Tamaño de la figura.        \n",
    "        \"\"\"\n",
    "        \n",
    "        n_modelos = len(self.modelos)\n",
    "        filas = math.ceil(n_modelos / n_cols)\n",
    "        f, axs = plt.subplots(filas, n_cols, figsize=size)\n",
    "        f.suptitle('Histogramas de Deviance', fontsize=16)        \n",
    "        axs = axs.ravel()\n",
    "        for i, ax in enumerate(axs):\n",
    "            ax = self.modelos[i].histograma_deviance(ax=ax)\n",
    "            ax.set_title(f\"{self.modelos[i].nombre}\")\n",
    "            \n",
    "    def mapas_residuales(self, tipo='deviance', n_cols=2, \n",
    "                         size=(20,10), clasificacion='quantiles', \n",
    "                         cmap='YlOrRd', legend=True):\n",
    "        \"\"\" Mapas de residuales para todos los modelos. \n",
    "        \n",
    "        \n",
    "            Args:\n",
    "                \n",
    "                tipo (str): deviance/pearson el tipo de residual a mapear\n",
    "                n_cols (int): Número de columnas en la figura.\n",
    "                size ((int, int)): Tamaño de la figura.\n",
    "                clasificacion (str): esquema de clasificación (mapclassify).\n",
    "                cmap (str): mapa de colores (matplotlib).\n",
    "                legend (bool): desplegar o no la leyenda.\n",
    "        \"\"\"\n",
    "        n_modelos = len(self.modelos)\n",
    "        filas = math.ceil(n_modelos / n_cols)\n",
    "        f, axs = plt.subplots(filas, n_cols, figsize=size)\n",
    "        f.suptitle(f'Mapas de residuales de {tipo}', fontsize=16)        \n",
    "        axs = axs.ravel()\n",
    "        for i, ax in enumerate(axs):\n",
    "            # TODO:size\n",
    "            ax = self.modelos[i].mapa_residuales(tipo=tipo, ax=ax, \n",
    "                                                 clasificacion=clasificacion, \n",
    "                                                 cmap=cmap, legend=legend)\n",
    "            ax.set_title(f\"{self.modelos[i].nombre}\")\n",
    "            \n",
    "    def scatterpĺots_moran(self, tipo=\"deviance\", n_cols=2, size=(20,10)):\n",
    "        \"\"\" Graficas de moran para todos los modelos.\n",
    "        \n",
    "        \n",
    "            Args:\n",
    "                \n",
    "                tipo (str): deviance/pearson el tipo de residual a mapear\n",
    "                n_cols (int): Número de columnas en la figura.\n",
    "                size ((int, int)): Tamaño de la figura.\n",
    "        \"\"\"\n",
    "        \n",
    "        n_modelos = len(self.modelos)\n",
    "        filas = math.ceil(n_modelos / n_cols)\n",
    "        f, axs = plt.subplots(filas, n_cols, figsize=size)\n",
    "        if tipo == \"deviance\":\n",
    "            titulo = 'Residuales de Deviance'\n",
    "        else:\n",
    "            titulo = 'Residuales de Pearson'\n",
    "        f.suptitle(titulo, fontsize=16)        \n",
    "        axs = axs.ravel()\n",
    "        for i, ax in enumerate(axs):\n",
    "            ax = self.modelos[i].scatterpĺot_moran(tipo=\"deviance\", ax=ax)\n",
    "            if tipo == \"deviance\":\n",
    "                moran = self.modelos[i].moran_dev_residuales\n",
    "            else:\n",
    "                moran = self.modelos[i].moran_p_residuales\n",
    "            \n",
    "            ax.set_title(f\"Modelo {self.modelos[i].nombre}: I de Moran {np.round(moran.I, 3)}, Significancia {moran.p_sim}\")\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b415ebb-0e3a-4197-a953-26db65d7ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables para el segundo modelo\n",
    "diccionario = get_diccionario_censo()\n",
    "censo = get_variables_censo()\n",
    "agregado = agrega_en_unidades(censo, diccionario)\n",
    "agregado = censo_a_tasas(agregado, diccionario)\n",
    "vars_viv = agregado[['VIVPAR_HAB', 'VPH_3YMASC']]\n",
    "vars_indice = ['P5_HLI', 'POB_AFRO', 'PCON_DISC', 'P3A5_NOA', \n",
    "               'P6A11_NOA', 'P12A14NOA', 'P15YM_AN', 'PSINDER', 'PDESOCUP']\n",
    "indice = IndicePCA(agregado, vars_indice)\n",
    "indice.calcula_indice()\n",
    "var_m1 = (vars_viv\n",
    "          .join(indice.indice.set_index('colonia_cve'))\n",
    "          .rename({'Índice': 'Concentración de Desventajas'}, axis=1))\n",
    "usos = get_uso_de_suelo()\n",
    "usos = agrega_uso_suelo(usos, unidades='colonias')\n",
    "var_m2 = var_m1.join(usos)\n",
    "# Dos capas de análisis\n",
    "ca1 = CapaDeAnalisis(Y, var_m1, 'colonias')\n",
    "ca2 = CapaDeAnalisis(Y, var_m2, 'colonias')\n",
    "# Ajustamos modelos\n",
    "m1 = ModeloGLM(ca1, sm.families.NegativeBinomial(),\"nulo\")\n",
    "r1 = m1.fit()\n",
    "m2 = ModeloGLM(ca2, sm.families.NegativeBinomial(), \"uso de suelo\")\n",
    "r2 = m2.fit()\n",
    "# Probamos la comparacion\n",
    "compara = ComparaModelos([m1,m2])\n",
    "assert type(compara.comparacion) == pd.DataFrame\n",
    "assert type(compara.diagnosticos) == pd.DataFrame\n",
    "compara = ComparaModelos([m1, m2], ['coef', 'P>|z|'], 3)\n",
    "assert type(compara.comparacion) == pd.DataFrame\n",
    "assert type(compara.diagnosticos) == pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b070bfc-0f7a-4637-849c-31504d54fa3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

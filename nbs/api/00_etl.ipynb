{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# etl\n",
    "\n",
    "> Extraer y transformar fuentes de datos sobre delincuencia en CDMX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import timedelta, date, datetime\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import h3\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "DATA_PATH = os.path.abspath(\"../../datos/\")\n",
    "DOWNLOADS_PATH = os.path.abspath(\"../../datos/descargas/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## procesa_registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def procesa_registros(records):\n",
    "    \"\"\"Hace el procesamineto básico de los records de carpetas o víctimas.\"\"\"\n",
    "    records.replace('NA', np.nan, inplace=True)\n",
    "    records.dropna(subset=['longitud', 'latitud'], how='any', inplace=True)\n",
    "    records = gpd.GeoDataFrame(records, geometry=gpd.points_from_xy(records.longitud, records.latitud))\n",
    "    records = records.set_crs(epsg=4326)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_carpetas_from_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_carpetas_from_api(limit=100):\n",
    "    \"\"\"Regresa un GeoDataFrame con los primeros `limit` registros de la base abierta.\"\"\"\n",
    "    url = f'https://datos.cdmx.gob.mx/api/3/action/datastore_search?resource_id=48fcb848-220c-4af0-839b-4fd8ac812c0f&limit={limit}'\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    records = r.json()['result']['records']\n",
    "    records = pd.DataFrame(records)\n",
    "    records = procesa_registros(records)\n",
    "    records['fecha_hechos'] = pd.to_datetime(records.fecha_hechos, dayfirst=True)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpetas = get_carpetas_from_api()\n",
    "assert type(carpetas) == gpd.GeoDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_victimas_from_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_victimas_from_api(limit=100):\n",
    "    \"\"\"Regresa un GeoDataFrame con los primeros `limit` registros de la base abierta de víctimas.\"\"\"\n",
    "    url = f'https://datos.cdmx.gob.mx/api/3/action/datastore_search?resource_id=d543a7b1-f8cb-439f-8a5c-e56c5479eeb5&limit={limit}'\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    records = r.json()['result']['records']\n",
    "    records = pd.DataFrame(records)\n",
    "    records = procesa_registros(records)\n",
    "    records['FechaHecho'] = pd.to_datetime(records.FechaHecho, dayfirst=True)\n",
    "    records = records.rename({'FechaHecho':'fecha_hechos',\n",
    "                              'Delito': 'delito',\n",
    "                              'Categoria': 'categoria'}, axis=1)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas = get_victimas_from_api()\n",
    "assert type(victimas) == gpd.GeoDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_historico_carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_historico_carpetas():\n",
    "    \"\"\"Regresa un GeoDataFrame con todos los registros de carpetas de investigación.\"\"\"\n",
    "    archivo = os.path.join(DOWNLOADS_PATH, 'carpetas_fiscalia.csv')\n",
    "    url = \"https://archivo.datos.cdmx.gob.mx/fiscalia-general-de-justicia/carpetas-de-investigacion-fgj-de-la-ciudad-de-mexico/carpetas_completa_febrero_2022.csv\"\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(archivo, 'wb').write(r.content)\n",
    "    records = pd.read_csv(archivo, low_memory=False)\n",
    "    records = procesa_registros(records)\n",
    "    records['fecha_hechos'] = pd.to_datetime(records.fecha_hechos, dayfirst=True)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpetas_todas = get_historico_carpetas()\n",
    "assert type(carpetas_todas) == gpd.GeoDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_historico_victimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_historico_victimas():\n",
    "    \"\"\"Regresa un GeoDataFrame con todos los registros de victimas en carpetas de investigación.\"\"\"\n",
    "    archivo = os.path.join(DOWNLOADS_PATH, 'victimas_carpetas_fiscalia.csv')\n",
    "    url = \"https://archivo.datos.cdmx.gob.mx/fiscalia-general-de-justicia/victimas-en-carpetas-de-investigacion-fgj/victimas_completa_febrero_2022.csv\"\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(archivo, 'wb').write(r.content)\n",
    "    records = pd.read_csv(archivo)\n",
    "    records = procesa_registros(records)\n",
    "    records['FechaHecho'] = pd.to_datetime(records.FechaHecho, dayfirst=True)\n",
    "    records = records.rename({'FechaHecho':'fecha_hechos',\n",
    "                              'Delito': 'delito',\n",
    "                              'Categoria': 'categoria'}, axis=1)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_todas = get_historico_victimas()\n",
    "assert type(victimas_todas) == gpd.GeoDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_carpetas_desde_archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_carpetas_desde_archivo(archivo):\n",
    "    \"\"\"Regresa un GeoDataFrame con los registros leídos de un archivo\"\"\"\n",
    "    records = pd.read_csv(archivo, low_memory=False)\n",
    "    records = procesa_registros(records)\n",
    "    records['fecha_hechos'] = pd.to_datetime(records.fecha_hechos, dayfirst=True)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpetas_todas = get_carpetas_desde_archivo(\"../../datos/descargas/carpetas_fiscalia.csv\")\n",
    "assert type(carpetas_todas) == gpd.GeoDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_victimas_desde_archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_victimas_desde_archivo(archivo):\n",
    "    \"\"\"Regresa un GeoDataFrame con los registros leídos de un archivo\"\"\"\n",
    "    records = pd.read_csv(archivo)\n",
    "    records = procesa_registros(records)\n",
    "    records['FechaHecho'] = pd.to_datetime(records.FechaHecho, dayfirst=True)\n",
    "    records = records.rename({'FechaHecho':'fecha_hechos',\n",
    "                              'Delito': 'delito',\n",
    "                              'Categoria': 'categoria'}, axis=1)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpetas_todas = get_victimas_desde_archivo(\"../../datos/descargas/victimas_carpetas_fiscalia.csv\")\n",
    "assert type(carpetas_todas) == gpd.GeoDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## descarga_manzanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def descarga_manzanas():\n",
    "    \"\"\" Descarga la geometría de manzanas con ids de cuadrante y colonia.\"\"\"\n",
    "    if os.path.exists(DOWNLOADS_PATH + 'manzanas_identificadores.gpkg'):\n",
    "        print(\"El archivo ya está descargado.\")\n",
    "    else:\n",
    "        url = \"https://www.dropbox.com/s/a370kmtknhgca2y/manzanas_identificadores.gpkg?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(DOWNLOADS_PATH + 'manzanas_identificadores.gpkg', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo ya está descargado.\n"
     ]
    }
   ],
   "source": [
    "descarga_manzanas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agrega_ids_espaciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def agrega_ids_espaciales(carpetas, metodo='manzanas', tolerancia=500):\n",
    "    \"\"\" Agrega ids de colonias y cuadrantes a la base de carpetas.\n",
    "    \n",
    "        Args:\n",
    "        \n",
    "            metodo (str): manzanas/poligonos. El método 'manzanas' hace un join_nearest con \n",
    "                          las manzanas que ya tienen ids de cuadrante y polígono; el método poligonos\n",
    "                          hace la unión espacial de los incidentes con las geometrías.\n",
    "            tolerancia (float): ¿qué tan lejos puede estar un incidente de una manzana? En el\n",
    "                                método 'poligonos' se ignora\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if 'manzana_cvegeo' in carpetas.columns:\n",
    "        carpetas = carpetas.drop(columns='colonia_cve')\n",
    "    if 'colonia_cve' in carpetas.columns:\n",
    "        carpetas = carpetas.drop(columns='colonia_cve')\n",
    "    if 'cuadrante_id' in carpetas.columns:\n",
    "        carpetas = carpetas.drop(columns='cuadrante_id')\n",
    "    if 'municipio_cvegeo' in carpetas.columns:\n",
    "        carpetas = carpetas.drop(columns='municipio_cvegeo')\n",
    "    if metodo == 'poligonos':\n",
    "        shapes = os.path.join(DATA_PATH, 'criminologia_capas.gpkg')\n",
    "        colonias = gpd.read_file(shapes, layer='colonias').drop(columns='colonia_geom_6362')\n",
    "        cuadrantes = gpd.read_file(shapes, layer='cuadrantes')\n",
    "        carpetas = (gpd.tools.sjoin(carpetas, colonias[['colonia_cve', 'colonia_nombre', 'municipio_cvegeo', 'geometry']])\n",
    "                    .drop(columns=['index_right'])\n",
    "                   )\n",
    "        carpetas = (gpd.tools.sjoin(carpetas, cuadrantes[['cuadrante_id', 'geometry']])\n",
    "                    .drop(columns=['index_right']))\n",
    "    elif metodo == 'manzanas':\n",
    "        crs_original = carpetas.crs\n",
    "        manzanas_pth = os.path.join(DOWNLOADS_PATH, 'manzanas_identificadores.gpkg')\n",
    "        manzanas = gpd.read_file(manzanas_pth)\n",
    "        manzanas['municipio_cvegeo'] = manzanas['CVE_ENT'] + manzanas['CVE_MUN']\n",
    "        carpetas = (carpetas\n",
    "                    .to_crs(manzanas.crs)\n",
    "                    .sjoin_nearest(manzanas[['CVEGEO', 'municipio_cvegeo', 'colonia_cve', \n",
    "                                             'cuadrante_id', 'geometry']], max_distance=tolerancia)\n",
    "                    .rename({'CVEGEO': 'manzana_cvegeo'}, axis=1)\n",
    "                    .drop(columns='index_right')\n",
    "                    .to_crs(crs_original))\n",
    "    else:\n",
    "        raise ValueError(\"'metodo' debe ser 'poligonos' o 'manzanas'\")\n",
    "    return carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruebas método polígono\n",
    "carpetas = agrega_ids_espaciales(carpetas, metodo='poligonos')\n",
    "assert 'colonia_cve' in carpetas.columns\n",
    "assert 'cuadrante_id' in carpetas.columns\n",
    "assert 'municipio_cvegeo' in carpetas.columns\n",
    "victimas = agrega_ids_espaciales(victimas, metodo='poligonos')\n",
    "assert 'colonia_cve' in victimas.columns\n",
    "assert 'cuadrante_id' in victimas.columns\n",
    "assert 'municipio_cvegeo' in victimas.columns\n",
    "# Pruebas método manzanas\n",
    "carpetas = agrega_ids_espaciales(carpetas, metodo='manzanas')\n",
    "assert 'colonia_cve' in carpetas.columns\n",
    "assert 'cuadrante_id' in carpetas.columns\n",
    "assert 'municipio_cvegeo' in carpetas.columns\n",
    "assert 'manzana_cvegeo' in carpetas.columns\n",
    "victimas = agrega_ids_espaciales(victimas, metodo='manzanas')\n",
    "assert 'colonia_cve' in victimas.columns\n",
    "assert 'cuadrante_id' in victimas.columns\n",
    "assert 'municipio_cvegeo' in victimas.columns\n",
    "assert 'manzana_cvegeo' in carpetas.columns\n",
    "# TODO prueba de excepción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agregar_categorias_carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def agregar_categorias_carpetas(carpetas, archivo_categorias=os.path.join(DATA_PATH, \"categorias_carpetas.csv\")):\n",
    "    \"\"\"Agrega una columna con categorías definidas por el usuario.\n",
    "\n",
    "      Las categorías tienen que venir en un csv con columnas incidente y categoria que\n",
    "      relacionen las categorías del usuario con la columna delitos de la base de carpetas.\n",
    "    \"\"\"\n",
    "    if 'categoria' in carpetas.columns:\n",
    "        carpetas = carpetas.drop(columns='categoria')\n",
    "    if 'incidente' in carpetas.columns:\n",
    "        carpetas = carpetas.drop(columns='incidente')\n",
    "    categorias = pd.read_csv(archivo_categorias)\n",
    "    carpetas = (carpetas\n",
    "                .merge(categorias, left_on='delito', right_on='incidente', how='left')\n",
    "                .drop(columns='incidente'))\n",
    "    return carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpetas = agregar_categorias_carpetas(carpetas)\n",
    "assert 'categoria' in carpetas.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agregar_categorias_victimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def agregar_categorias_victimas(carpetas, archivo_categorias=os.path.join(DATA_PATH, \"categorias_victimas.csv\")):\n",
    "    \"\"\"Columnas con niveles definidos por el usuario\n",
    "\n",
    "      Las categorías tienen que venir en un csv con columnas llamadas Nivel 1, Nivel 2 ...\n",
    "      que relacionen los niveles con las columnas Delito y Categoría en la base de Víctimas.\n",
    "    \"\"\"\n",
    "    columnas_nivel = [c for c in carpetas.columns if 'Nivel' in c]\n",
    "    if len(columnas_nivel):\n",
    "        carpetas = carpetas.drop(columns=columnas_nivel)\n",
    "    categorias = pd.read_csv(archivo_categorias)\n",
    "    carpetas = (carpetas\n",
    "                .merge(categorias, left_on='delito', right_on='Delito', how='left')\n",
    "                .rename({'categoria_x': 'categoria'}, axis=1)\n",
    "                )\n",
    "    return carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas = agregar_categorias_victimas(victimas)\n",
    "assert 'Nivel 1' in victimas.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exporta_datos_visualizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def exporta_datos_visualizador(carpetas, archivo_resultado,\n",
    "                               fecha_inicio=pd.to_datetime('01/01/2019'),\n",
    "                               tipo='victimas'):\n",
    "    \"\"\" Escribe en archivo_resultado un csv para consumirse en el visualizador.\n",
    "\n",
    "        La opción tipo=victimas/carpetas controla si los datos de entrada son carpetas o victimas.\n",
    "    \"\"\"\n",
    "    columnas = ['fecha_hechos', 'delito', 'municipio_cvegeo',\n",
    "                'colonia_cve', 'cuadrante_id', 'categoria', 'lat', 'long']\n",
    "    if tipo == 'carpetas':\n",
    "        columnas = columnas + ['categoria']\n",
    "    elif tipo == 'victimas':\n",
    "        columnas_nivel = [c for c in carpetas.columns if 'Nivel' in c]\n",
    "        columnas = columnas + columnas_nivel\n",
    "    carpetas['lat'] = carpetas.geometry.y\n",
    "    carpetas['long'] = carpetas.geometry.x\n",
    "    carpetas = carpetas[columnas]\n",
    "    carpetas = carpetas.loc[carpetas.fecha_hechos >= fecha_inicio]\n",
    "    carpetas.to_csv(archivo_resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exporta_datos_visualizador(carpetas, \"../../datos/salidas/carpetas.csv\", tipo='carpetas')\n",
    "exporta_datos_visualizador(victimas, \"../../datos/salidas/victimas.csv\", tipo='victimas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serie_de_tiempo_categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def serie_de_tiempo_categoria(carpetas, fecha_inicio, categoria, freq='M'):\n",
    "    \"\"\" Regresa una serie de tiempo con los agregados por `freq` de la `categoria`.\n",
    "\n",
    "        parameters:\n",
    "        carpetas: incidentes, deben traer la columna categoria\n",
    "        fecha_inicio: pd.datetime fecha del inicio de la serie\n",
    "        categoria: nombre de la categoría a agregar (`agregar_categorias_de_usuario`)\n",
    "        freq: frecuencia de agregación (https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)\n",
    "    \"\"\"\n",
    "    carpetas = carpetas.loc[carpetas.fecha_hechos >= fecha_inicio]\n",
    "    carpetas = carpetas.loc[carpetas.categoria == categoria]\n",
    "    serie = (carpetas\n",
    "             .set_index('fecha_hechos')[['categoria']]\n",
    "             .resample(freq)\n",
    "             .size()\n",
    "             .reset_index()\n",
    "             .rename({0:categoria}, axis=1)\n",
    "            )\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_hechos</th>\n",
       "      <th>Robo a pasajero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fecha_hechos  Robo a pasajero\n",
       "0   2016-01-31                1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie = serie_de_tiempo_categoria(carpetas, pd.to_datetime('01/01/2016'), 'Robo a pasajero')\n",
    "serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serie_tiempo_categorias_unidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def serie_tiempo_categorias_unidades(datos, fecha_inicio, tipo='victimas',\n",
    "                                     geografia='colonias',freq='W',\n",
    "                                     categorias=['Nivel 1']):\n",
    "    \"\"\" Regresa una serie de tiempo con los agregados por `freq` para categorias y\n",
    "        la geografía especificada.\n",
    "\n",
    "        parameters:\n",
    "        datos: víctimas/carpetas, deben tener agregadas las categorías de usuario\n",
    "        fecha_inicio: pd.datetime fecha del inicio de la serie\n",
    "        tipo: carpetas/victimas\n",
    "        geografia: 'colonias/cuadrantes'\n",
    "        freq: frecuencia de agregación (https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)\n",
    "        categorias: lista de las categorías para agregar. Las columnas deben existir en la base\n",
    "    \"\"\"\n",
    "    dummies = pd.get_dummies(datos[categorias])\n",
    "    datos = datos.loc[datos.fecha_hechos >= fecha_inicio]\n",
    "    datos = pd.concat([datos, dummies], axis=1)\n",
    "    if geografia == 'colonias':\n",
    "        id_vars = ['colonia_nombre', 'colonia_cve']\n",
    "    elif geografia == 'cuadrantes':\n",
    "        id_vars = ['cuadrante_id']\n",
    "    else:\n",
    "        return #RAISE!!!!!\n",
    "    serie = (datos[['fecha_hechos', *id_vars, *list(dummies.columns)]]\n",
    "             .set_index('fecha_hechos')\n",
    "             .groupby([pd.Grouper(freq=\"M\"), *id_vars])\n",
    "             .sum())\n",
    "    serie = serie.reset_index().melt(id_vars=['fecha_hechos', *id_vars])\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['colonia_nombre'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m serie \u001b[38;5;241m=\u001b[39m \u001b[43mserie_tiempo_categorias_unidades\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvictimas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m01/01/2019\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m serie\n",
      "Cell \u001b[0;32mIn [47], line 25\u001b[0m, in \u001b[0;36mserie_tiempo_categorias_unidades\u001b[0;34m(datos, fecha_inicio, tipo, geografia, freq, categorias)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;66;03m#RAISE!!!!!\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m serie \u001b[38;5;241m=\u001b[39m (\u001b[43mdatos\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfecha_hechos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mid_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdummies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     26\u001b[0m          \u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha_hechos\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m          \u001b[38;5;241m.\u001b[39mgroupby([pd\u001b[38;5;241m.\u001b[39mGrouper(freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;241m*\u001b[39mid_vars])\n\u001b[1;32m     28\u001b[0m          \u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m     29\u001b[0m serie \u001b[38;5;241m=\u001b[39m serie\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mmelt(id_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha_hechos\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39mid_vars])\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m serie\n",
      "File \u001b[0;32m~/miniconda3/envs/criminologia_cdmx/lib/python3.10/site-packages/geopandas/geodataframe.py:1428\u001b[0m, in \u001b[0;36mGeoDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   1423\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1424\u001b[0m \u001b[39m    If the result is a column containing only 'geometry', return a\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m \u001b[39m    GeoSeries. If it's a DataFrame with any columns of GeometryDtype,\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m \u001b[39m    return a GeoDataFrame.\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1428\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(key)\n\u001b[1;32m   1429\u001b[0m     geo_col \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_geometry_column_name\n\u001b[1;32m   1430\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, Series) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result\u001b[39m.\u001b[39mdtype, GeometryDtype):\n",
      "File \u001b[0;32m~/miniconda3/envs/criminologia_cdmx/lib/python3.10/site-packages/pandas/core/frame.py:3811\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3810\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3811\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3813\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/criminologia_cdmx/lib/python3.10/site-packages/pandas/core/indexes/base.py:6108\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6106\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6108\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6110\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6112\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/criminologia_cdmx/lib/python3.10/site-packages/pandas/core/indexes/base.py:6171\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6168\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6170\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6171\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['colonia_nombre'] not in index\""
     ]
    }
   ],
   "source": [
    "serie = serie_tiempo_categorias_unidades(victimas, pd.to_datetime('01/01/2019'))\n",
    "serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## punto_to_hexid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def punto_to_hexid(punto, resolution):\n",
    "    \"\"\"Regresa el hexid (h3) del punto.\"\"\"\n",
    "    return h3.geo_to_h3(punto.y, punto.x, resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agrega_en_hexagonos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def agrega_en_hexagonos(puntos, resolution):\n",
    "    \"\"\"Regresa un GeoDataFrame con las cuentas de puntos agregadas en hexágonos.\n",
    "\n",
    "       params:\n",
    "       puntos: GeoDataFrame: los puntos a agregar\n",
    "       resolution: int: la resolución en uber.h3\n",
    "    \"\"\"\n",
    "    puntos.loc[:,'hex_id'] = puntos.loc[:,'geometry'].apply(punto_to_hexid, args=[resolution])\n",
    "    by_hex = puntos.groupby('hex_id').size().reset_index()\n",
    "    # by_hex['geometry'] = by_hex['hex_id'].apply(lambda hex_id: Polygon(h3.h3_to_geo_boundary(hex_id)))\n",
    "    by_hex['geometry'] = by_hex['hex_id'].apply(lambda hex_id: Polygon([x[::-1] for x in h3.h3_to_geo_boundary(hex_id)]))\n",
    "    by_hex = gpd.GeoDataFrame(by_hex).rename({0:'incidentes'}, axis=1).set_crs(epsg=4326)\n",
    "    return by_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('criminologia_cdmx')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

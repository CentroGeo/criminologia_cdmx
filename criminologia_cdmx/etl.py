# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/api/00_etl.ipynb.

# %% auto 0
__all__ = ['DATA_PATH', 'DOWNLOADS_PATH', 'procesa_registros', 'get_carpetas_from_api', 'get_victimas_from_api',
           'descarga_historico_carpetas', 'descarga_historico_victimas', 'get_carpetas_desde_archivo',
           'get_victimas_desde_archivo', 'descarga_manzanas', 'agrega_ids_espaciales', 'agregar_categorias_carpetas',
           'agregar_categorias_victimas', 'exporta_datos_visualizador', 'serie_de_tiempo_categoria',
           'serie_tiempo_categorias_unidades', 'punto_to_hexid', 'agrega_en_hexagonos']

# %% ../nbs/api/00_etl.ipynb 3
import os
import glob
import itertools
from typing import Union
from pathlib import Path
import numpy as np
import pandas as pd
import geopandas as gpd
from datetime import timedelta, date, datetime
import seaborn as sns
import requests
import h3
from shapely.geometry import Polygon, Point

# %% ../nbs/api/00_etl.ipynb 4
def __get_data_path():
    " Regresa el path absoluto al direcorio de datos."
    data_name = 'datos'
    data_path = Path.cwd()
    while data_path != data_path.parent and not (data_path/data_name).exists(): data_path = data_path.parent
    if not (data_path/data_name).exists(): data_path = data_path
    return data_path/data_name
DATA_PATH = __get_data_path()
DOWNLOADS_PATH = DATA_PATH/'descargas'

# %% ../nbs/api/00_etl.ipynb 6
def procesa_registros(records:pd.DataFrame # viene de leer datos de carpetas o víctimas
    )-> gpd.GeoDataFrame: # el mismo pero con los registros corregidos
    """Hace el procesamineto básico de los records de carpetas o víctimas."""
    records.replace('NA', np.nan, inplace=True)
    records.dropna(subset=['longitud', 'latitud'], how='any', inplace=True)
    records = gpd.GeoDataFrame(records, geometry=gpd.points_from_xy(records.longitud, records.latitud))
    records = records.set_crs(epsg=4326)
    return records

# %% ../nbs/api/00_etl.ipynb 8
def get_carpetas_from_api(limit:int=100 # Cuántos registros traigo del api
    )-> Union[gpd.GeoDataFrame, None]:
    """Regresa un GeoDataFrame con los primeros `limit` registros de la base abierta."""
    url = f'https://datos.cdmx.gob.mx/api/3/action/datastore_search?resource_id=48fcb848-220c-4af0-839b-4fd8ac812c0f&limit={limit}'
    try:
        r = requests.get(url, allow_redirects=True)
    except: # Quizá deberíamos cachar cosas específicas
        return None
    records = r.json()['result']['records']
    records = pd.DataFrame(records)
    records = procesa_registros(records)
    records['fecha_hechos'] = pd.to_datetime(records.fecha_hechos, dayfirst=True)
    return records

# %% ../nbs/api/00_etl.ipynb 11
def get_victimas_from_api(limit=100 # Cuántos registros traigo del api
    )-> Union[gpd.GeoDataFrame, None]:
    """Regresa un GeoDataFrame con los primeros `limit` registros de la base abierta de víctimas."""
    url = f'https://datos.cdmx.gob.mx/api/3/action/datastore_search?resource_id=d543a7b1-f8cb-439f-8a5c-e56c5479eeb5&limit={limit}'
    try:
        r = requests.get(url, allow_redirects=True)
    except:
        return None
    records = r.json()['result']['records']
    records = pd.DataFrame(records)
    records = procesa_registros(records)
    records['FechaHecho'] = pd.to_datetime(records.FechaHecho, dayfirst=True)
    records = records.rename({'FechaHecho':'fecha_hechos',
                              'Delito': 'delito',
                              'Categoria': 'categoria'}, axis=1)
    return records

# %% ../nbs/api/00_etl.ipynb 14
def descarga_historico_carpetas()->os.path:
    """Descarga el histórico de carpetas y regrersa el path al archivo."""
    absp = os.path.abspath(os.path.join(DOWNLOADS_PATH, 'carpetas_fiscalia.csv'))
    url = "https://archivo.datos.cdmx.gob.mx/fiscalia-general-de-justicia/carpetas-de-investigacion-fgj-de-la-ciudad-de-mexico/carpetas_completa_febrero_2022.csv"
    if os.path.exists(absp):
        print("El archivo ya está descargado")
    else:
        r = requests.get(url, allow_redirects=True)
        open(absp, 'wb').write(r.content)
    return absp


# %% ../nbs/api/00_etl.ipynb 17
def descarga_historico_victimas()->os.path:
    """Descarga el histórico de víctimas y regrersa el path al archivo."""
    absp = os.path.abspath(os.path.join(DOWNLOADS_PATH, 'victimas_carpetas_fiscalia.csv'))
    url = "https://archivo.datos.cdmx.gob.mx/fiscalia-general-de-justicia/victimas-en-carpetas-de-investigacion-fgj/victimas_completa_febrero_2022.csv"
    if os.path.exists(absp):
        print("El archivo ya está descargado")
    else:
        r = requests.get(url, allow_redirects=True)
        open(absp, 'wb').write(r.content)
    return absp


# %% ../nbs/api/00_etl.ipynb 20
def get_carpetas_desde_archivo(archivo:os.path # El path al archivo (`descarga_historico_carpetas`)
    )->gpd.GeoDataFrame:
    """Regresa un GeoDataFrame con los registros leídos de un archivo"""
    records = pd.read_csv(archivo, low_memory=False)
    records = procesa_registros(records)
    records['fecha_hechos'] = pd.to_datetime(records.fecha_hechos, dayfirst=True)
    return records

# %% ../nbs/api/00_etl.ipynb 23
def get_victimas_desde_archivo(archivo # El path al archivo (`descarga_historico_victimas`)
    )->os.path:
    """Regresa un GeoDataFrame con los registros leídos de un archivo"""
    records = pd.read_csv(archivo)
    records = procesa_registros(records)
    records['FechaHecho'] = pd.to_datetime(records.FechaHecho, dayfirst=True)
    records = records.rename({'FechaHecho':'fecha_hechos',
                              'Delito': 'delito',
                              'Categoria': 'categoria'}, axis=1)
    return records

# %% ../nbs/api/00_etl.ipynb 26
def descarga_manzanas()->os.path:
    """ Descarga la geometría de manzanas con ids de cuadrante y colonia."""
    absp = os.path.abspath(os.path.join(DOWNLOADS_PATH, 'manzanas_identificadores.gpkg'))
    if os.path.exists(absp):
        print("El archivo ya está descargado.")
    else:
        url = "https://www.dropbox.com/s/a370kmtknhgca2y/manzanas_identificadores.gpkg?dl=1"
        r = requests.get(url, allow_redirects=True)
        open(absp, 'wb').write(r.content)
    return absp

# %% ../nbs/api/00_etl.ipynb 29
def agrega_ids_espaciales(carpetas: gpd.GeoDataFrame, # Datos de carpetas o victimas (p.ej. `get_victimas_desde_archivo`)
                          metodo:str='manzanas', # manzanas/poligonos
                          tolerancia:float=500 # ¿qué tan lejos puede estar un incidente de una manzana?
    )->gpd.GeoDataFrame:
    """ Agrega ids de colonias y cuadrantes a la base de carpetas."""
    
    if 'manzana_cvegeo' in carpetas.columns:
        carpetas = carpetas.drop(columns='colonia_cve')
    if 'colonia_cve' in carpetas.columns:
        carpetas = carpetas.drop(columns='colonia_cve')
    if 'cuadrante_id' in carpetas.columns:
        carpetas = carpetas.drop(columns='cuadrante_id')
    if 'municipio_cvegeo' in carpetas.columns:
        carpetas = carpetas.drop(columns='municipio_cvegeo')
    if metodo == 'poligonos':
        shapes = os.path.join(DATA_PATH, 'criminologia_capas.gpkg')
        colonias = gpd.read_file(shapes, layer='colonias').drop(columns='colonia_geom_6362')
        cuadrantes = gpd.read_file(shapes, layer='cuadrantes')
        carpetas = (gpd.tools.sjoin(carpetas, colonias[['colonia_cve', 'colonia_nombre', 'municipio_cvegeo', 'geometry']])
                    .drop(columns=['index_right'])
                   )
        carpetas = (gpd.tools.sjoin(carpetas, cuadrantes[['cuadrante_id', 'geometry']])
                    .drop(columns=['index_right']))
    elif metodo == 'manzanas':
        crs_original = carpetas.crs
        manzanas_pth = os.path.join(DOWNLOADS_PATH, 'manzanas_identificadores.gpkg')
        manzanas = gpd.read_file(manzanas_pth)
        manzanas['municipio_cvegeo'] = manzanas['CVE_ENT'] + manzanas['CVE_MUN']
        carpetas = (carpetas
                    .to_crs(manzanas.crs)
                    .sjoin_nearest(manzanas[['CVEGEO', 'municipio_cvegeo', 'colonia_cve', 
                                             'cuadrante_id', 'geometry']], max_distance=tolerancia)
                    .rename({'CVEGEO': 'manzana_cvegeo'}, axis=1)
                    .drop(columns='index_right')
                    .to_crs(crs_original))
    else:
        raise ValueError("'metodo' debe ser 'poligonos' o 'manzanas'")
    return carpetas

# %% ../nbs/api/00_etl.ipynb 33
def agregar_categorias_carpetas(carpetas:gpd.GeoDataFrame, # Carpetas de investigación (p.ej. `get_carpetas_desde_archivo`) 
                                archivo_categorias:os.path # path al archivo con las categorías
                              )->gpd.GeoDataFrame:
    """Agrega una columna con categorías definidas por el usuario.

      Las categorías tienen que venir en un csv con columnas incidente y categoria que
      relacionen las categorías del usuario con la columna delitos de la base de carpetas.
    """
    if 'categoria' in carpetas.columns:
        carpetas = carpetas.drop(columns='categoria')
    if 'incidente' in carpetas.columns:
        carpetas = carpetas.drop(columns='incidente')
    categorias = pd.read_csv(archivo_categorias)
    carpetas = (carpetas
                .merge(categorias, left_on='delito', right_on='incidente', how='left')
                .drop(columns='incidente'))
    return carpetas

# %% ../nbs/api/00_etl.ipynb 38
def agregar_categorias_victimas(carpetas:gpd.GeoDataFrame, # Víctimas en Carpetas de investigación (p.ej. `get_victimas_desde_archivo`)
                                archivo_categorias:os.path# path al archivo con las categorías
                                )-> gpd.GeoDataFrame:
    """Columnas con niveles definidos por el usuario

      Las categorías tienen que venir en un csv con columnas llamadas Nivel 1, Nivel 2 ...
      que relacionen los niveles con las columnas Delito y Categoría en la base de Víctimas.
    """
    columnas_nivel = [c for c in carpetas.columns if 'Nivel' in c]
    if len(columnas_nivel):
        carpetas = carpetas.drop(columns=columnas_nivel)
    categorias = pd.read_csv(archivo_categorias)
    carpetas = (carpetas
                .merge(categorias, left_on='delito', right_on='Delito', how='left')
                .rename({'categoria_x': 'categoria'}, axis=1)
                )
    return carpetas

# %% ../nbs/api/00_etl.ipynb 43
def exporta_datos_visualizador(carpetas:gpd.GeoDataFrame, # Datos de carpetas o victimas (p.ej. `get_victimas_desde_archivo`)
                               archivo_resultado:os.path, # A dónde exportamos el archivo
                               fecha_inicio:pd.DatetimeTZDtype=pd.to_datetime('01/01/2019'), # Dónde empezamos
                               tipo:str='victimas')->None:
    """ Escribe en archivo_resultado un csv para consumirse en el visualizador.

        La opción tipo=victimas/carpetas controla si los datos de entrada son carpetas o victimas.
    """
    columnas = ['fecha_hechos', 'delito', 'municipio_cvegeo',
                'colonia_cve', 'cuadrante_id', 'categoria', 'lat', 'long']
    if tipo == 'carpetas':
        columnas = columnas + ['categoria']
    elif tipo == 'victimas':
        columnas_nivel = [c for c in carpetas.columns if 'Nivel' in c]
        columnas = columnas + columnas_nivel
    carpetas['lat'] = carpetas.geometry.y
    carpetas['long'] = carpetas.geometry.x
    carpetas = carpetas[columnas]
    carpetas = carpetas.loc[carpetas.fecha_hechos >= fecha_inicio]
    carpetas.to_csv(archivo_resultado)

# %% ../nbs/api/00_etl.ipynb 46
def serie_de_tiempo_categoria(carpetas:gpd.GeoDataFrame, # incidentes, deben traer la columna categoria (p.ej. 'agregar_categorias_carpetas')
                              fecha_inicio:pd.DatetimeTZDtype, # fecha del inicio de la serie
                              categoria, # nombre de la categoría a agregar (`agregar_categorias_carpetas`)
                              freq:str='M' # frecuencia de agregación (https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)
                              )-> pd.DataFrame:
    """ Regresa una serie de tiempo con los agregados por `freq` de la `categoria`."""
    carpetas = carpetas.loc[carpetas.fecha_hechos >= fecha_inicio]
    carpetas = carpetas.loc[carpetas.categoria == categoria]
    serie = (carpetas
             .set_index('fecha_hechos')[['categoria']]
             .resample(freq)
             .size()
             .reset_index()
             .rename({0:categoria}, axis=1)
            )
    return serie

# %% ../nbs/api/00_etl.ipynb 49
def serie_tiempo_categorias_unidades(datos:gpd.GeoDataFrame, # víctimas/carpetas, deben tener agregadas las categorías de usuario
                                     fecha_inicio:pd.DatetimeTZDtype, # fecha del inicio de la serie 
                                     tipo:str='victimas', # carpetas/victimas
                                     geografia:str='colonias',# colonias/cuadrantes
                                     freq:str='W', #frecuencia de agregación (https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)
                                     categorias:list=['Nivel 1'] # lista de las categorías para agregar. Las columnas deben existir en la base
                                     )->pd.DataFrame:
    """ Regresa una serie de tiempo con los agregados por `freq` para categorias y
        la geografía especificada."""
    dummies = pd.get_dummies(datos[categorias])
    datos = datos.loc[datos.fecha_hechos >= fecha_inicio]
    datos = pd.concat([datos, dummies], axis=1)
    if geografia == 'colonias':
        id_vars = ['colonia_nombre', 'colonia_cve']
    elif geografia == 'cuadrantes':
        id_vars = ['cuadrante_id']
    else:
        return #RAISE!!!!!
    serie = (datos[['fecha_hechos', *id_vars, *list(dummies.columns)]]
             .set_index('fecha_hechos')
             .groupby([pd.Grouper(freq="M"), *id_vars])
             .sum())
    serie = serie.reset_index().melt(id_vars=['fecha_hechos', *id_vars])
    return serie

# %% ../nbs/api/00_etl.ipynb 52
def punto_to_hexid(punto:Point, # Punto para obtener el hex_id
                  resolution: int # Escala de H3
                  ):
    """Regresa el hexid (h3) del punto."""
    return h3.geo_to_h3(punto.y, punto.x, resolution)

# %% ../nbs/api/00_etl.ipynb 54
def agrega_en_hexagonos(puntos:gpd.GeoDataFrame, # Los datos que vamos a pasar a hexágonos
                       resolution:int # Escala de H3
                       ):
    """Regresa un GeoDataFrame con las cuentas de puntos agregadas en hexágonos."""
    puntos.loc[:,'hex_id'] = puntos.loc[:,'geometry'].apply(punto_to_hexid, args=[resolution])
    by_hex = puntos.groupby('hex_id').size().reset_index()
    # by_hex['geometry'] = by_hex['hex_id'].apply(lambda hex_id: Polygon(h3.h3_to_geo_boundary(hex_id)))
    by_hex['geometry'] = by_hex['hex_id'].apply(lambda hex_id: Polygon([x[::-1] for x in h3.h3_to_geo_boundary(hex_id)]))
    by_hex = gpd.GeoDataFrame(by_hex).rename({0:'incidentes'}, axis=1).set_crs(epsg=4326)
    return by_hex

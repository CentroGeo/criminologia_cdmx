# AUTOGENERATED! DO NOT EDIT! File to edit: 01_patrones_espacio_temporales.ipynb (unless otherwise specified).

__all__ = ['construye_malla', 'ajusta_bandwidth_kde', 'kde2D', 'malla_comun', 'get_lista_datos', 'KDE_hotspots',
           'razones_de_incidentes', 'smer_KDE']

# Cell
from sklearn.neighbors import KernelDensity
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold
import pandas as pd
import geopandas as gpd
import xarray as xr
import holoviews as hv
import numpy as np
import matplotlib.pyplot as plt
from .etl import *
from functools import partial

hv.extension('bokeh')
hv.renderer('bokeh').theme = 'dark_minimal'

# Cell
def construye_malla(datos, size):
    """ Regresa una malla (np.meshgrid) ajustada al extent de los datos,
        con el tamaño de celda especificado.

        Args:
            datos (GeoDataFrame): carpetas o víctimas
            size (float): tamaño de las celdas (en las unidades de la proyección)

    """
    xmin, ymin, xmax, ymax = datos.geometry.total_bounds
    xgrid = np.arange(xmin, xmax, size)
    ygrid = np.arange(ymin, ymax, size)
    X, Y = np.meshgrid(xgrid, ygrid)
    return (X, Y)

# Cell
def ajusta_bandwidth_kde(datos, bandwidth_space, size=1000,
                         malla=None, n_jobs=-1, metric="euclidean"):
    """ Regresa el valor de bandwidth con mejor log likelihood.

        Parametros:

            datos (GeoDataFrame):  víctimas o carpetas
            bandwith_space (np.linspace):  con el espacio de búsqueda
            size (float): Tamaño de la celda (en las unidades de la proyección).
                          Si se especifica malla se ignora
            malla (np.meshgrid): la malla en la que se va a ajustar el KDE, si es None se calcula
            n_jobs (int): número de procesos a usar (default = -1)
            metric (str): métrica a usar para calcular las distancias (default euclidean)
    """
    if malla is None:
        xx, yy = construye_malla(datos, size)
    else:
        xx = malla[0]
        yy = malla[1]
    xy_sample = np.vstack([yy.ravel(), xx.ravel()]).T
    x = datos.geometry.x.to_numpy()
    y = datos.geometry.y.to_numpy()
    xy_train  = np.vstack([y, x]).T
    grid = GridSearchCV(KernelDensity(metric=metric), bandwidth_space, n_jobs=n_jobs)
    grid.fit(xy_train)
    return grid.best_estimator_.bandwidth

# Cell

def kde2D(datos, bandwidth, size=1000, malla=None):
    """ Regresa una matriz con la densidad de kernel para los datos.

        Parametros:

            datos (GeoDataFrame):  víctimas o carpetas
            bandwith: ancho del kernel gaussiano
            size (float): Tamaño de la celda (en las unidades de la proyección).
                          Si se especifica malla se ignora
            metric (str): métrica a usar para calcular las distancias (default euclidean)
            malla (np.meshgrid): la malla en la que se va a ajustar el KDE, si es None se calcula
    """
    x = datos.geometry.x.to_numpy()
    y = datos.geometry.y.to_numpy()
    if malla is None:
        X, Y = construye_malla(datos, size)
    else:
        X = malla[0]
        Y = malla[1]
    XY = np.vstack([Y.ravel(), X.ravel()]).T
    xy_train = np.vstack([y, x]).T
    kde = KernelDensity(bandwidth=bandwidth)
    kde.fit(xy_train)
    # Z = kde.score_samples(XY)
    Z = np.exp(kde.score_samples(XY))
    return X, Y, np.reshape(Z, X.shape)

# Cell
def malla_comun(datos, size):
    """ Regresa las mallas (formato np y xarray) más pequeñas (de tamaño size)
        que contienen a todos los datos.

        Args:
            datos(list(GeoDataGrames)): lista con los datos para la malla común.
            size (float): tamaño de las celdas en la malla.
    """
    envolventes = [d.geometry.unary_union.envelope for d in datos]
    envolventes = gpd.GeoSeries(envolventes)
    xmin, ymin, xmax, ymax = envolventes.unary_union.envelope.bounds
    xgrid = np.arange(xmin, xmax, size)
    ygrid = np.arange(ymin, ymax, size)
    X, Y = np.meshgrid(xgrid, ygrid)
    return {'xr_grid':(xgrid, ygrid), 'np_grid':(X,Y)}

# Cell
def get_lista_datos(carpetas, fechas, categorias, offset):
    """ Regresa una lista de GeoDataFrames con los datos segmentados en fechas
        para la categoría seleccionada.

    """
    fechas = fechas.copy()
    fecha_inicio = fechas[0] - pd.to_timedelta(offset)
    fechas.insert(0, fecha_inicio)
    intervalos = [(fechas[i-1], f) for i, f in enumerate(fechas[1:],1)]
    datos = []
    for intervalo in intervalos:
        datos_intervalo = carpetas.loc[(carpetas['fecha_hechos'].between(*intervalo, inclusive='left')) &
                                       (carpetas['categoria'].isin(categorias))]
        datos.append(datos_intervalo)
    return datos

# Cell
def KDE_hotspots(carpetas, fechas, size, categorias, offset, malla=None, bw=1000):
    """ Ajusta kdes egregando los datos sobre cada categoria e intervalo de fecha.

       Args:
           carpetas (GeoDataFrame): Incidentes (carpetas/victimas), si viene `malla` se ignora size
           size (float): Tamaño de la celda (en las unidades de la proyección)
           fechas list(pd.datetime): extremos (derechos) de los intervalos de tiempo
           categorias: Lista de categorías para calcular el KDE
           offset: intervalo para agregar antes de la primera fecha,
                   p.ej: "30 days" si los intervalos son mensuales
           malla (dict): Obtenida con `malla_comun`.
           bw: bandwidth para la estimación del KDE

       Salida:
       serie_kde: xr.DataArray con coordenadas (lat, long, tiempo) que contiene los arrays para
                  cda intervalo.
    """
    if 'categoria' not in carpetas.columns:
        raise ValueError('Es necesario correr asignar categorías a los delitos.')
    datos = get_lista_datos(carpetas, fechas, categorias, "30 days")
    if malla is None:
        malla = malla_comun(datos, size)
    kde2D_p = lambda d: kde2D(d, bw, size=size, malla=malla['np_grid'])
    kdes = map(kde2D_p, datos)
    kdes = [k[2] for k in kdes]
    tiempo = fechas
    serie_kde = np.array(kdes)
    lat = malla['xr_grid'][1]
    lon = malla['xr_grid'][0]
    serie_kde = xr.DataArray(serie_kde,
                             coords={"latitud":lat, "longitud":lon, 'tiempo':tiempo},
                             dims=["tiempo","latitud", "longitud"])
    serie_kde.name = "Densidad"
    return serie_kde

# Cell
def razones_de_incidentes(carpetas, fechas, categorias, offset, size, bw):
    """ Regresa un xr.Dataset con los xr.DataArray para lass series por categoría, base y las razones."""
    datos_categoria = get_lista_datos(carpetas, fechas, categorias, offset)
    categorias_todas = list(carpetas[carpetas.categoria.notnull()]['categoria'].unique())
    categorias_todas = set(categorias_todas) - set(categorias)
    datos_base = get_lista_datos(carpetas, fechas, categorias_todas, offset)
    datos_completos = datos_categoria + datos_base
    malla = malla_comun(datos_completos, size)
    kdes_categoria = KDE_hotspots(carpetas, fechas, size,
                                                categorias, offset, bw=bw, malla=malla)
    kdes_base = KDE_hotspots(carpetas, fechas, size,
                                                categorias_todas, offset, bw=bw, malla=malla)
    # TODO: vectorizar esta operación np.divide(a, b, out=np.zeros_like(a), where=b!=0)
    razones = kdes_categoria / kdes_base
    ds = xr.Dataset({"Serie categorias":kdes_categoria,
                     "Serie base":kdes_base,
                     "Serie razones":razones})
    return ds

# Cell
def smer_KDE(carpetas, fechas, categorias, offset, size, bw):
    """Regresa los mapas de razon y las intensidades de la categoría para las `fechas` seleccionadas."""
    series = razones_de_incidentes(carpetas, fechas, categorias, offset, size, bw)
    avg = series['Serie razones'].mean(dim='tiempo')
    std = series['Serie razones'].std(dim='tiempo')
    intensidad = (series['Serie razones'] - avg) / std
    series = series.assign(intensidad=intensidad)
    ps = []
    for i in range(len(fechas)):
        n_h = (series['Serie razones'].isel(tiempo=i) <= series['Serie razones'])
        n_h = n_h.sum(dim='tiempo')
        p = n_h / (len(fechas) + 1)
        ps.append(p)
    ps = xr.concat(ps, dim=series.coords['tiempo'])
    series = series.assign(p_values=ps)
    return series